package frc.robot.subsystems;

import java.util.List;
import java.util.Optional;
import java.util.function.Consumer;
import java.util.function.Supplier;

import org.photonvision.EstimatedRobotPose;
import org.photonvision.PhotonCamera;
import org.photonvision.PhotonPoseEstimator;
import org.photonvision.targeting.PhotonPipelineResult;
import org.photonvision.targeting.PhotonTrackedTarget;

import com.ctre.phoenix6.Utils;
import com.ctre.phoenix6.swerve.SwerveDrivetrain.SwerveDriveState;

import dev.doglog.DogLog;
import dev.doglog.DogLogOptions;

import edu.wpi.first.math.Matrix;
import edu.wpi.first.math.VecBuilder;
import edu.wpi.first.math.geometry.Pose2d;
import edu.wpi.first.math.geometry.Rotation2d;
import edu.wpi.first.math.numbers.N1;
import edu.wpi.first.math.numbers.N3;
import edu.wpi.first.util.sendable.SendableBuilder;
import edu.wpi.first.wpilibj.smartdashboard.Field2d;
import edu.wpi.first.wpilibj.smartdashboard.SmartDashboard;
import edu.wpi.first.wpilibj2.command.Command;
import edu.wpi.first.wpilibj2.command.SubsystemBase;
import edu.wpi.first.wpilibj2.command.button.Trigger;
import frc.robot.LimelightHelpers;
import frc.robot.LimelightHelpers.PoseEstimate;
import frc.robot.constants.VisionConstants.limelight;
import frc.robot.constants.VisionConstants.photonvision;

public class Vision extends SubsystemBase {
    
    public CommandSwerveDrivetrain drivetrain;
    public poseEstimateConsumer poseConsumer;

    public LimelightHelpers.PoseEstimate megaTag2 = new PoseEstimate();

    public Field2d limelightField = new Field2d();

    public Matrix<N3, N1> currentStdDevs = limelight.kMegaTag2StdDevs;

    private PhotonCamera leftCamera;
    private PhotonPoseEstimator leftCameraEstimator = new PhotonPoseEstimator(photonvision.kTagLayout, photonvision.kRobotToLeftCamera);

    private PhotonCamera rightCamera;
    private PhotonPoseEstimator rightCameraEstimator = new PhotonPoseEstimator(photonvision.kTagLayout, photonvision.kRobotToRightCamera);
    
    private LimelightHelpers.PoseEstimate cachedMegaTag2 = new PoseEstimate();
    private Pose2d testPose = new Pose2d(5.0, 5.0, new Rotation2d(90.0));
    private double cachedRobotHeading = 0.0;
    private double cachedRobotRotationRate = 0.0;
    private boolean cachedMegaTagValid = false;
    private boolean cachedAreTagsSeen = false;
    private boolean cachedIsRobotSlowEnough = false;
    private boolean cachedIsLimelightPoseValid = false;
    private boolean cachedIsLeftPhotonPoseValid = false;
    private boolean cachedIsRightPhotonPoseValid = false;
    private double limelightTimestamp;
    private double testTimestamp;

    /**
     * Constructor.
     */
    public Vision(CommandSwerveDrivetrain drivetrain, Supplier<SwerveDriveState> swerveDriveState, poseEstimateConsumer poseConsumer) {
        this.drivetrain = drivetrain;
        
        this.poseConsumer = poseConsumer;
        //this.poseConsumer = this.drivetrain::addVisionMeasurement;

        this.setLimelightRobotPosition();
        //In the constructor, set the IMU mode to 1, so the limelight IMU is seeded with the robot gyro heading.
        LimelightHelpers.SetIMUMode(limelight.kName, 1);
        LimelightHelpers.SetRobotOrientation(limelight.kName, this.getRobotHeading(), 0.0, 0.0, 0.0, 0.0, 0.0);

        leftCamera = new PhotonCamera(photonvision.kLeftName);
        rightCamera = new PhotonCamera(photonvision.kRightName);

        SmartDashboard.putData("Vision", this);
        SmartDashboard.putData("Vision/Pose", this.limelightField);
    }

    /**
     * Set the position of the Limelight relative to the center of the robot.
     * This only needs to be run during initialization.
     */
    private void setLimelightRobotPosition() {
        LimelightHelpers.setCameraPose_RobotSpace(
            limelight.kName,
            limelight.kForwardOffset,
            limelight.kSideOffset,
            limelight.kUpOffset,
            limelight.kRollOffset,
            limelight.kPitchOffset,
            limelight.kYawOffset
        );
    }

    /**
     * Command the limelight to start using its internal IMU for the pose estimate it produces.
     */
    private void setLimelightToInternalIMU() {
        LimelightHelpers.SetIMUMode(limelight.kName, 2);
    }

    /**
     * Returns true if the pose estimate is not 'null' and a valid target is in view.
     * 'Valid' in this case means the limelight actually sent data and sees a valid target; this method is not checking if the data makes sense.
     * @param poseEstimate
     * @return
     */
    private boolean isMegaTagValid(LimelightHelpers.PoseEstimate poseEstimate) {
        return (poseEstimate != null) && LimelightHelpers.getTV(limelight.kName);
    }

    /**
     * Returns true if the photonvision pose estimate is not empty.
     * This method is not checking if the data makes sense.
     * @param camera
     * @param result
     * @return
     */
    private boolean isPhotonEstimateValid(PhotonPoseEstimator camera, PhotonPipelineResult result) {
        return camera.estimateCoprocMultiTagPose(result).isEmpty();
    }

    /**
     * Returns true if the latest megaTag estimate identifies at least the amount of tags passed into this method.
     * @param megaTag2Estimate
     * @param tagCount
     * @return
     */
    private boolean areLimelightTagsSeen(LimelightHelpers.PoseEstimate megaTag2Estimate, int tagCount) {
        return megaTag2Estimate.tagCount >= tagCount;
    }

    /**
     * Returns true if the photonvision result contains at least the amount of tags passed into this method.
     * @param photonResult
     * @param tagCount
     * @return
     */
    private boolean arePhotonTagsSeen(PhotonPipelineResult photonResult, int tagCount) {
        return photonResult.hasTargets() && (photonResult.getTargets().size() >= tagCount);
    }

    /**
     * Returns true if the rotational velocity of the robot is less than the value passed into this method.
     * @param maximumRotationRate
     * @return
     */
    private boolean isRobotSlowEnough(double maximumRotationRate) {
        return this.cachedRobotRotationRate <= maximumRotationRate;
    }

    /**
     * Signifies that the latest estimated pose is valid if:
     * 1. The megaTag2 estimate is valid.
     * 2. At least one AprilTag was seen.
     * 3. The robot is not turning too fast.
     * @param megaTag2Estimate
     * @return
     */
    private boolean isLimelightPoseValid(LimelightHelpers.PoseEstimate megaTag2Estimate) {
        //3.3 radians per second is currently 75% of our maximum rotational speed.
        return this.isMegaTagValid(megaTag2Estimate) && this.areLimelightTagsSeen(megaTag2Estimate, 1) && this.isRobotSlowEnough(3.3);
    }

    /**
     * Signifies that the latest estimated photon pose is valid if:
     * 1. The photon pose estimate is valid.
     * 2. At least one AprilTag was seen.
     * 3. The robot is not turning too fast.
     * @param camera
     * @param result
     * @return
     */
    private boolean isPhotonvisionPoseValid(PhotonPoseEstimator camera, PhotonPipelineResult result) {
        //3.3 radian per second is currently 75% of our maximum rotational speed.
        return this.isPhotonEstimateValid(camera, result) && this.arePhotonTagsSeen(result, 1) && this.isRobotSlowEnough(3.3);
    }

    /**
     * Return the current robot heading, in degrees.
     * The current heading is based on the robot pose, because the pigeon yaw doesn't wrap around 0 - 360 degrees.
     */
    private double getRobotHeading() {
        return this.drivetrain.getState().Pose.getRotation().getDegrees();
    }

    /**
     * Return the absolute angular velocity of the robot, in radians per second.
     * @return
     */
    private double getRobotRotationRate() {
        return Math.abs(this.drivetrain.getState().Speeds.omegaRadiansPerSecond);
    }

    /**
     * Return the pose component of the current megaTag2 estimate.
     * @return
     */
    private Pose2d getCurrentLimelightPose() {
        return this.megaTag2.pose;
    }

    /**
     * Return the pose component of the current left swerve camera estimate.
     * @param camera
     * @return
     */
    private Pose2d getCurrentLeftPhotonPose(PhotonPoseEstimator camera) {
        return this.megaTag2.pose;
    }

    /**
     * Process the latest camera results from the photon camera.
     * We still need to determine the return type of this method, and how it passes the estimate back into the periodic method.
     * @param photonResults
     * @param photonEstimator
     */
    private void processPhotonCameraResults(List<PhotonPipelineResult> photonResults, PhotonPoseEstimator photonEstimator) {
        Optional<EstimatedRobotPose> visionEst = Optional.empty();
        for (var result : photonResults) {
            visionEst = photonEstimator.estimateCoprocMultiTagPose(result);
            if (visionEst.isEmpty()) {
                visionEst = photonEstimator.estimateLowestAmbiguityPose(result);
            }
            this.updateEstimationStdDevs(photonEstimator, visionEst, result.getTargets());
            visionEst.ifPresent( est -> {
                var stddev = getEstimationStdDevs();
                poseConsumer.accept(est.estimatedPose.toPose2d(), est.timestampSeconds, stddev);
            });

            this.drivetrain.addVisionMeasurement(visionEst.get().estimatedPose.toPose2d(), visionEst.get().timestampSeconds, this.getEstimationStdDevs());
        } 
    }

    /**
     * Calculates new standard deviations. This algorithm is a heuristic that creates dynamic standard deviations based on number of tags, estimation strategy, and distance from the tags.
     * @param camera
     * @param estimatedPose The estimated pose to guess the standard deviations for.
     * @param targets All targets in this camera frame.
     */
    private void updateEstimationStdDevs(PhotonPoseEstimator camera, Optional<EstimatedRobotPose> estimatedPose, List<PhotonTrackedTarget> targets) {
        if (estimatedPose.isEmpty()) {
            // No pose input. Default to single-tag std devs
            this.currentStdDevs = photonvision.kSingleTagStdDevs;
        } else {
            // Pose present. Start running Heuristic
            var estStdDevs = photonvision.kSingleTagStdDevs;
            int numTags = 0;
            double avgDist = 0;

            // Precalculation - See how many tags we found, and calculate an average-distance metric
            for (var tgt : targets) {
                var tagPose = camera.getFieldTags().getTagPose(tgt.getFiducialId());
                if (tagPose.isEmpty()) continue;
                numTags++;
                avgDist += tagPose.get().toPose2d().getTranslation().getDistance(estimatedPose.get().estimatedPose.toPose2d().getTranslation());
            }

            if (numTags == 0) {
                // No tags visible. Default to single-tag std devs
                this.currentStdDevs = photonvision.kSingleTagStdDevs;
            } else {
                // One or more tags visible, run the full heuristic.
                avgDist /= numTags;
                // Decrease std devs if multiple targets are visible
                if (numTags > 1) estStdDevs = photonvision.kMultiTagStdDevs;
                // Increase std devs based on (average) distance
                if (numTags == 1 && avgDist > 4)
                    estStdDevs = VecBuilder.fill(Double.MAX_VALUE, Double.MAX_VALUE, Double.MAX_VALUE);
                else estStdDevs.times(1 + (avgDist * avgDist / 30));
                this.currentStdDevs = estStdDevs;
            }
        }
    }

    /**
     * Returns the latest standard deviations of the estimated pose from {@link #getEstimatedGlobalPose()}, for use with {@link edu.wpi.first.math.estimator.SwerveDrivePoseEstimator SwerveDrivePoseEstimator}. This should only be used when there are targets visible.
     * @return
     */
    public Matrix<N3, N1> getEstimationStdDevs() {
        return this.currentStdDevs;
    }

    /**
     * Returns a string of the name of the currently running command.
     * If no command is running, return "No Command".
     * @return
     */
    private String getCurrentCommandName() {
        if (this.getCurrentCommand() == null) {
            return "No Command";
        }
        else {
            return this.getCurrentCommand().getName();
        }
        // Refactoring this method with a ternary operator.
        // return (this.getCurrentCommand == null) ? "No Command" : this.getCurrentCommand().getName();
    }

    public Trigger addLimelightPose = new Trigger(() -> {return this.cachedIsLimelightPoseValid;});
    public Trigger addLeftPhotonPose = new Trigger(() -> {return this.cachedIsLeftPhotonPoseValid;});
    public Trigger addRightPhotonPose = new Trigger(() -> {return this.cachedIsRightPhotonPoseValid;});

    /**
     * Add the current megaTag2 pose estimate to the drivetrain pose estimate.
     * @param drivetrain
     * @return
     */
    public Command addMegaTag2(Supplier<CommandSwerveDrivetrain> drivetrain) {
        return run(
            () -> {
                limelightTimestamp = Utils.getCurrentTimeSeconds();
                drivetrain.get().setVisionMeasurementStdDevs(VecBuilder.fill(0.5, 0.5, 9999999));
                drivetrain.get().addVisionMeasurement(megaTag2.pose, megaTag2.timestampSeconds);
            }
        ).withName("Adding Limelight Vision Measurement").ignoringDisable(true);
    }

    /**
     * Add the current test pose estimate to the drivetrain pose estimate.
     * @param drivetrain
     * @return
     */
    public Command addTestPose(Supplier<CommandSwerveDrivetrain> drivetrain) {
        return run(
            () -> {
                testTimestamp = Utils.getCurrentTimeSeconds();
                drivetrain.get().setVisionMeasurementStdDevs(limelight.kMegaTag2StdDevs);
                drivetrain.get().addVisionMeasurement(this.testPose, this.testTimestamp);
            }
        ).withName("Adding Test Pose Measurement").ignoringDisable(true);
    }

    /**
     * Switch the limelight to use its internal IMU for the pose estimate.
     * @return
     */
    public Command switchToInternalIMU() {
        return runOnce(() -> {this.setLimelightToInternalIMU();}).withName("Setting Limelight to IMU Mode 2").ignoringDisable(true);
    }

    @Override
    public void initSendable(SendableBuilder builder) {
        builder.addStringProperty("Command", this::getCurrentCommandName, null);
        builder.addDoubleProperty("Robot Heading", () -> {return this.cachedRobotHeading;}, null);
        builder.addDoubleProperty("Robot Rotation Rate", () -> {return this.cachedRobotRotationRate;}, null);
        builder.addBooleanProperty("Is Robot Slow Enough", () -> {return this.cachedIsRobotSlowEnough;}, null);
        builder.addDoubleProperty("Test Timestamp", () -> {return this.testTimestamp;}, null);
    }

    @Override
    public void periodic() {
        // This method will be called once per scheduler run.
     
        // Start by caching important values.
        // By caching these values, any other code that requires them will use the same values for the current 20 ms loop.
        this.cachedRobotHeading = this.getRobotHeading();
        this.cachedRobotRotationRate = this.getRobotRotationRate();
        this.cachedIsRobotSlowEnough = this.isRobotSlowEnough(3.3);
        this.cachedMegaTag2 = LimelightHelpers.getBotPoseEstimate_wpiBlue_MegaTag2(limelight.kName);
        this.cachedMegaTagValid = this.isMegaTagValid(this.cachedMegaTag2);

        // Only check the number of tags and validity of the pose if the megatag is valid.
        // Only update the megaTag if the most recent megaTag is valid.
        if (this.cachedMegaTagValid) {
            this.cachedAreTagsSeen = this.areLimelightTagsSeen(this.cachedMegaTag2, 1);
            this.cachedIsLimelightPoseValid = this.isLimelightPoseValid(this.cachedMegaTag2);
            this.megaTag2 = this.cachedMegaTag2;
            // Log Limelight pose estimate
            Pose2d llPose = this.megaTag2.pose;
            DogLog.log("Vision/Limelight/X" , llPose.getX());
            DogLog.log("Vision/Limelight/Y" , llPose.getY());
            DogLog.log("Vision/Limelight/RotDeg" , llPose.getRotation().getDegrees());
        } else {
            // If the megaTag isn't valid, obviously no tags can be seen and the pose isn't valid.
            this.cachedAreTagsSeen = false;
            this.cachedIsLimelightPoseValid = false;
        }

        if (cachedIsLimelightPoseValid) {
            poseConsumer.accept(this.getCurrentLimelightPose(), this.megaTag2.timestampSeconds, limelight.kMegaTag2StdDevs);
        }

        // Every loop, seed the limelight IMU with the current robot heading.
        LimelightHelpers.SetRobotOrientation(limelight.kName, this.cachedRobotHeading, 0.0, 0.0, 0.0, 0.0, 0.0);

        // Every loop, update the odometry with the current pose estimated by the limelight.
        limelightField.setRobotPose(this.getCurrentLimelightPose());

        /* This code is for the photonvision estimate.  Currently, I don't need it, since we don't have the photonvision.
        Optional<EstimatedRobotPose> visionEst = Optional.empty();
        for (var result : leftCamera.getAllUnreadResults()) {
            visionEst = leftCameraEstimator.estimateCoprocMultiTagPose(result);
            if (visionEst.isEmpty()) {
                visionEst = leftCameraEstimator.estimateLowestAmbiguityPose(result);
            }
            this.updateEstimationStdDevs(leftCameraEstimator, visionEst, result.getTargets());

            this.drivetrain.addVisionMeasurement(visionEst.get().estimatedPose.toPose2d(), visionEst.get().timestampSeconds, this.getEstimationStdDevs());
        }
        */
    }

    @Override
    public void simulationPeriodic() {
        // This method will be called once per scheduler run during simulation.

        // Update the odometry to the test pose, for test purposes.
        // Add some noise to the test pose - although this is a annoying way to do it.
        this.testPose = new Pose2d(5.0 + Math.random(), 5.0 + Math.random(), new Rotation2d(Math.random() * 180.0));
        this.limelightField.setRobotPose(this.testPose);
        this.testTimestamp = Utils.getCurrentTimeSeconds();

        poseConsumer.accept(this.testPose, this.testTimestamp, limelight.kMegaTag2StdDevs);
    }

    @FunctionalInterface
    public static interface poseEstimateConsumer {
        public void accept(Pose2d pose, double timestamp, Matrix<N3, N1> measurementStdDevs);
    }
}
